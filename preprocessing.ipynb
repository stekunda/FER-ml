{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torch.utils.data import ConcatDataset\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from skimage.feature import local_binary_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 48\n",
    "IMG_WIDTH = 48\n",
    "\n",
    "# Path to the training data\n",
    "TRAIN_DATA_PATH = os.path.join(os.getcwd(), '../FER with DL/data', 'train')\n",
    "\n",
    "# Path to the test data\n",
    "TEST_DATA_PATH = os.path.join(os.getcwd(), '../FER with DL/data', 'test')\n",
    "\n",
    "# Defining transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load the datasets\n",
    "train_dataset = ImageFolder(TRAIN_DATA_PATH, transform=transform)\n",
    "test_dataset = ImageFolder(TEST_DATA_PATH, transform=transform)\n",
    "\n",
    "# Create the dataloader for validation set only, train data still needs to be augmented\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "\n",
    "def plot_sample_images(path, n=10):\n",
    "    \"\"\"Plot n sample images from the given path.\"\"\"\n",
    "    class_folders = [os.path.join(path, f) for f in os.listdir(path) if os.path.isdir(os.path.join(path, f))]\n",
    "    images = []\n",
    "    for folder in class_folders:\n",
    "        images.extend([os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "    if len(images) < n:\n",
    "        print(f\"Only found {len(images)} images in {path}.\")\n",
    "        n = len(images)\n",
    "    fig, axs = plt.subplots(2, n//2, figsize=(15, 6))\n",
    "    for i in range(n):\n",
    "        img_path = images[i]\n",
    "        img = read_image(img_path)\n",
    "        ax = axs[i // (n//2), i % (n//2)]\n",
    "        ax.imshow(img.permute(1, 2, 0).squeeze(), cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.show()\n",
    "\n",
    "def plot_label_distribution(path):\n",
    "    \"\"\"Plot the distribution of labels in the given path.\"\"\"\n",
    "    labels = [folder for folder in os.listdir(path) if os.path.isdir(os.path.join(path, folder))]\n",
    "    counts = [len(os.listdir(os.path.join(path, label))) for label in labels]\n",
    "    plt.bar(labels, counts)\n",
    "    plt.title('Distribution of Labels')\n",
    "    plt.xlabel('Label')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "# Plot sample images and label distribution for the training data\n",
    "plot_sample_images(TRAIN_DATA_PATH)\n",
    "plot_label_distribution(TRAIN_DATA_PATH)\n",
    "\n",
    "# Plot sample images and label distribution for the test data\n",
    "plot_sample_images(TEST_DATA_PATH)\n",
    "plot_label_distribution(TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot images from a certain emotion folder\n",
    "def plot_sample_images(path, angry_files, n=10):\n",
    "    \"\"\"Plot n sample images from the given path.\"\"\"\n",
    "    # Only consider the specific folder\n",
    "    class_folders = [os.path.join(path, angry_files)]\n",
    "    images = []\n",
    "    for folder in class_folders:\n",
    "        images.extend([os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "    if len(images) < n:\n",
    "        print(f\"Only found {len(images)} images in {path}.\")\n",
    "        n = len(images)\n",
    "    fig, axs = plt.subplots(2, n//2, figsize=(15, 6))\n",
    "    for i in range(n):\n",
    "        img_path = images[i]\n",
    "        img = read_image(img_path)\n",
    "        ax = axs[i // (n//2), i % (n//2)]\n",
    "        ax.imshow(img.permute(1, 2, 0).squeeze(), cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.show()\n",
    "\n",
    "def plot_label_distribution(path, angry_files):\n",
    "    \"\"\"Plot the distribution of labels in the given path.\"\"\"\n",
    "    # Only consider the specific folder\n",
    "    labels = [angry_files]\n",
    "    counts = [len(os.listdir(os.path.join(path, label))) for label in labels]\n",
    "    plt.bar(labels, counts)\n",
    "    plt.title('Distribution of Labels')\n",
    "    plt.xlabel('Label')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "# Specify the folder you want to inspect\n",
    "angry_files = 'happy'\n",
    "\n",
    "# Plot sample images and label distribution for the specific folder in the training data\n",
    "plot_sample_images(TRAIN_DATA_PATH, angry_files)\n",
    "# plot_label_distribution(TRAIN_DATA_PATH, angry_files)\n",
    "\n",
    "# Plot sample images and label distribution for the specific folder in the test data\n",
    "# plot_sample_images(TEST_DATA_PATH, angry_files)\n",
    "# plot_label_distribution(TEST_DATA_PATH, angry_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for bad data in the classes\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def plot_sample_images(path, specific_folder, n=10):\n",
    "    \"\"\"Plot n sample images from the given path.\"\"\"\n",
    "    # Only consider the specific folder\n",
    "    class_folders = [os.path.join(path, specific_folder)]\n",
    "    images = []\n",
    "    for folder in class_folders:\n",
    "        images.extend([os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "    if len(images) < n:\n",
    "        print(f\"Only found {len(images)} images in {path}.\")\n",
    "        n = len(images)\n",
    "\n",
    "    # Load all images and calculate the mean image\n",
    "    image_data = [np.array(Image.open(img_path)) for img_path in images]\n",
    "    mean_image = np.mean(image_data, axis=0)\n",
    "\n",
    "    # Calculate the Euclidean distance from each image to the mean image\n",
    "    distances = [distance.euclidean(img.flatten(), mean_image.flatten()) for img in image_data]\n",
    "\n",
    "    # Find the n images with the largest distances\n",
    "    outlier_indices = np.argsort(distances)[-n:]\n",
    "    outlier_images = [images[i] for i in outlier_indices]\n",
    "\n",
    "    # Plot the outlier images\n",
    "    fig, axs = plt.subplots(2, n//2, figsize=(15, 6))\n",
    "    for i, img_path in enumerate(outlier_images):\n",
    "        img = read_image(img_path)\n",
    "        ax = axs[i // (n//2), i % (n//2)]\n",
    "        ax.imshow(img.permute(1, 2, 0).squeeze(), cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.show()\n",
    "\n",
    "# Use the function\n",
    "plot_sample_images(TRAIN_DATA_PATH, 'happy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes roughly 4 minutes to run this cell\n",
    "\n",
    "# Oversampling the disgust samples since we don't have many samples\n",
    "\n",
    "# Define additional transformations for data augmentation\n",
    "augment_transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create a new dataset with only the \"disgust\" images\n",
    "disgust_dataset = [img for img in train_dataset if img[1]\n",
    "                   == train_dataset.class_to_idx['disgust']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Convert Tensor to PIL Image\n",
    "to_pil = ToPILImage()\n",
    "\n",
    "# Apply data augmentation to the \"disgust\" images\n",
    "# There are 436 disgust files in the training data so the value after range is the mutiplier\n",
    "augmented_disgust_dataset = [(augment_transform(to_pil(img[0])), img[1])\n",
    "                             for _ in range(8) for img in disgust_dataset]\n",
    "\n",
    "print(type(augmented_disgust_dataset[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(augmented_disgust_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the original dataset with the augmented \"disgust\" images\n",
    "train_dataset = ConcatDataset([train_dataset, augmented_disgust_dataset])\n",
    "\n",
    "# Create the train DataLoader now that disgust images have been augmented\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Print details about the train and test datasets\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of testing samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Binary patterns (LBP) Feature Extraction Implementation\n",
    "def extract_features_lbp(data_loader):\n",
    "    # Parameters for LBP\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    # Initialize an empty list to store the feature vectors\n",
    "    features = []\n",
    "    labels = []\n",
    "    # Process each batch of images\n",
    "    for images, batch_labels in data_loader:\n",
    "        for i in range(len(images)):\n",
    "            image = images[i].numpy().squeeze()\n",
    "            lbp = local_binary_pattern(image, n_points, radius)\n",
    "            # Flatten the LBP image and add it to the list of feature vectors\n",
    "            features.append(lbp.ravel())\n",
    "            labels.append(batch_labels[i].item())\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigenfaces Feature Extraction Implmentation\n",
    "def extract_features_eigenfaces(data_loader):\n",
    "    # Initialize an empty list to store the images and labels\n",
    "    images = []\n",
    "    labels = []\n",
    "    # Process each batch of images\n",
    "    for batch_images, batch_labels in data_loader:\n",
    "        for i in range(len(batch_images)):\n",
    "            image = batch_images[i].numpy().squeeze()\n",
    "            # Flatten the image and add it to the list of images\n",
    "            images.append(image.ravel())\n",
    "            labels.append(batch_labels[i].item())\n",
    "    # Convert the lists to numpy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    # Apply PCA to the images\n",
    "    pca = PCA(n_components=150)\n",
    "    features = pca.fit_transform(images)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fisherfaces Feature Extraction Implementation\n",
    "def extract_features_fisherfaces(data_loader):\n",
    "    # Initialize an empty list to store the images and labels\n",
    "    images = []\n",
    "    labels = []\n",
    "    # Process each batch of images\n",
    "    for batch_images, batch_labels in data_loader:\n",
    "        for i in range(len(batch_images)):\n",
    "            image = batch_images[i].numpy().squeeze()\n",
    "            # Flatten the image and add it to the list of images\n",
    "            images.append(image.ravel())\n",
    "            labels.append(batch_labels[i].item())\n",
    "    # Convert the lists to numpy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    # Apply PCA to the images\n",
    "    pca = PCA(n_components=150)\n",
    "    pca_result = pca.fit_transform(images)\n",
    "    # Apply LDA to the PCA result\n",
    "    lda = LDA(n_components=None)\n",
    "    features = lda.fit_transform(pca_result, labels)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes roughly 4 minutes to run this cell\n",
    "# Subsititute the function name based on the feature extraction method you want to use\n",
    "X_train, y_train = extract_features_lbp(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes roughly 4 minutes to run this cell\n",
    "# Subsititute the function name based on the feature extraction method you want to use\n",
    "X_test, y_test = extract_features_lbp(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Number of feature vectors: {len(X_train)}\")\n",
    "print(f\"Shape of a feature vector: {X_train[0].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import seaborn as sns\n",
    "\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test, model):\n",
    "    # Create a SVM (Support Vector Machine) classifier\n",
    "    # clf = KNeighborsClassifier()\n",
    "    clf = model\n",
    "\n",
    "    # Train the model with the training data and labels\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Get the name of the model\n",
    "    model_name = type(model).__name__\n",
    "\n",
    "    # Create the filename\n",
    "    filename = f'{model_name}_model.pth'\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model, filename)\n",
    "\n",
    "    # Predict the labels of the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate the model accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Truth')\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100}%\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"K-Nearest Neighbors Classifier\")\n",
    "train_and_evaluate(X_train, y_train, X_test, y_test, KNeighborsClassifier())\n",
    "\n",
    "print(\"Random Forest Classifier\")\n",
    "train_and_evaluate(X_train, y_train, X_test, y_test, RandomForestClassifier())\n",
    "\n",
    "print(\"Decision Tree Classifier\")\n",
    "train_and_evaluate(X_train, y_train, X_test, y_test, DecisionTreeClassifier())\n",
    "\n",
    "print(\"Gaussian Naive Bayes Classifier\")\n",
    "train_and_evaluate(X_train, y_train, X_test, y_test, GaussianNB())\n",
    "\n",
    "print(\"Support Vector Machine Classifier\")\n",
    "train_and_evaluate(X_train, y_train, X_test, y_test, SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the class labels and their corresponding indices\n",
    "print(test_dataset.class_to_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DA515",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
